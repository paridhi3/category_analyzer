openai.BadRequestError: Unsupported data type

File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 128, in exec_func_with_error_handling
    result = func()
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 669, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
    ~~~~^^^^^^^^^^^^^^^^^^^^^^^
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\main2.py", line 136, in <module>
    vectorstore = create_vector_store(file_text, selected_chat_file.replace(".", "_"))
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\main2.py", line 69, in create_vector_store
    vector_store = Chroma.from_texts(
        chunks,
    ...<2 lines>...
        persist_directory=f".chromadb_{safe_name}"
    )
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\langchain_community\vectorstores\chroma.py", line 843, in from_texts
    chroma_collection.add_texts(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        texts=batch[3] if batch[3] else [],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        metadatas=batch[2] if batch[2] else None,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        ids=batch[0],
        ^^^^^^^^^^^^^
    )
    ^
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\langchain_community\vectorstores\chroma.py", line 277, in add_texts
    embeddings = self._embedding_function.embed_documents(texts)
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\langchain_community\embeddings\openai.py", line 671, in embed_documents
    return self._get_len_safe_embeddings(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        texts, engine=engine, chunk_size=chunk_size
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\langchain_community\embeddings\openai.py", line 497, in _get_len_safe_embeddings
    response = embed_with_retry(
        self,
        input=tokens[i : i + _chunk_size],
        **self._invocation_params,
    )
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\langchain_community\embeddings\openai.py", line 120, in embed_with_retry
    return embeddings.client.create(**kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
           ~~~~~~~~~~^
        "/embeddings",
        ^^^^^^^^^^^^^^
    ...<8 lines>...
        cast_to=CreateEmbeddingResponse,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\openai\_base_client.py", line 1256, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File "C:\Users\703417007_agarwal\Desktop\CASE-STUDY-BUILDER\Categorizer\.venv\Lib\site-packages\openai\_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
